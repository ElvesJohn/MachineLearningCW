{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder,MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_pivot(labelgroup, yvalue, dataset, SZOnly = False):\n",
    "    if SZOnly:\n",
    "        dataset = dataset.loc[dataset.Diagnosis == 0]\n",
    "    \n",
    "    grouped = (dataset.groupby([labelgroup])[yvalue].value_counts(normalize = True).rename('percentage').reset_index())\n",
    "    pivot = pd.pivot_table(grouped, index = labelgroup, columns = yvalue, values = 'percentage', aggfun = 'sum')\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/dahaixing/Documents/Coursework/DeepLearning/MLCW/MachineLearningCW/MS4S16_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_impu(data):\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    mean_tired = data['Tired'].replace(['NaN','inf'], pd.np.nan).astype(float).mean()\n",
    "    mean_tired = data['Tired'].replace([pd.np.nan, pd.np.inf], pd.np.nan).mean()\n",
    "    data['Tired'].replace(['NaN','inf'], mean_tired)\n",
    "    data.replace([pd.np.nan, pd.np.inf], [mean_tired, mean_tired], inplace=True)\n",
    "    return data\n",
    "\n",
    "def data_remove(data):\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Anhedonia</th>\n",
       "      <th>Apathy</th>\n",
       "      <th>Appetite</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Content</th>\n",
       "      <th>Delusion</th>\n",
       "      <th>Dep_Mood</th>\n",
       "      <th>Focus</th>\n",
       "      <th>Hallucination</th>\n",
       "      <th>...</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>Psychomotor</th>\n",
       "      <th>Rumination</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Stress</th>\n",
       "      <th>Suspicious</th>\n",
       "      <th>Tension</th>\n",
       "      <th>Tired</th>\n",
       "      <th>Unusual_Thought</th>\n",
       "      <th>Withdrawal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.505800</td>\n",
       "      <td>6.502860</td>\n",
       "      <td>2.478849</td>\n",
       "      <td>27.070029</td>\n",
       "      <td>6.519924</td>\n",
       "      <td>0.279407</td>\n",
       "      <td>2.637389</td>\n",
       "      <td>5.727062</td>\n",
       "      <td>6.519924</td>\n",
       "      <td>65.073832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101376</td>\n",
       "      <td>4.680583</td>\n",
       "      <td>5.685816</td>\n",
       "      <td>7.011266</td>\n",
       "      <td>4.916418</td>\n",
       "      <td>2.754909</td>\n",
       "      <td>4.920667</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.480266</td>\n",
       "      <td>3.958121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500016</td>\n",
       "      <td>1.488151</td>\n",
       "      <td>1.730810</td>\n",
       "      <td>14.202618</td>\n",
       "      <td>1.474846</td>\n",
       "      <td>0.834494</td>\n",
       "      <td>1.440347</td>\n",
       "      <td>3.284501</td>\n",
       "      <td>1.474846</td>\n",
       "      <td>223.943469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301880</td>\n",
       "      <td>1.482692</td>\n",
       "      <td>2.161891</td>\n",
       "      <td>1.410841</td>\n",
       "      <td>2.220262</td>\n",
       "      <td>1.496126</td>\n",
       "      <td>1.962342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.410475</td>\n",
       "      <td>1.469444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098854</td>\n",
       "      <td>-3.211011</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>1.299964</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-2.127037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.299964</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024974</td>\n",
       "      <td>-0.409032</td>\n",
       "      <td>2.144726</td>\n",
       "      <td>-3.257788</td>\n",
       "      <td>-2.346238</td>\n",
       "      <td>-2.183456</td>\n",
       "      <td>0.366650</td>\n",
       "      <td>-1.981307</td>\n",
       "      <td>-0.825919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.495361</td>\n",
       "      <td>1.265128</td>\n",
       "      <td>16.724108</td>\n",
       "      <td>5.528181</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>1.629919</td>\n",
       "      <td>4.678095</td>\n",
       "      <td>5.528181</td>\n",
       "      <td>4.113962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.697870</td>\n",
       "      <td>4.042552</td>\n",
       "      <td>6.058402</td>\n",
       "      <td>3.443683</td>\n",
       "      <td>1.703462</td>\n",
       "      <td>3.565482</td>\n",
       "      <td>4.491580</td>\n",
       "      <td>1.486439</td>\n",
       "      <td>2.969534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.485527</td>\n",
       "      <td>2.427409</td>\n",
       "      <td>25.165292</td>\n",
       "      <td>6.498042</td>\n",
       "      <td>0.064259</td>\n",
       "      <td>2.558146</td>\n",
       "      <td>6.752196</td>\n",
       "      <td>6.498042</td>\n",
       "      <td>12.764604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.720156</td>\n",
       "      <td>5.521805</td>\n",
       "      <td>6.980519</td>\n",
       "      <td>5.096416</td>\n",
       "      <td>2.735108</td>\n",
       "      <td>5.247353</td>\n",
       "      <td>5.513508</td>\n",
       "      <td>2.388994</td>\n",
       "      <td>3.962131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.489218</td>\n",
       "      <td>3.642059</td>\n",
       "      <td>35.447666</td>\n",
       "      <td>7.519759</td>\n",
       "      <td>0.215773</td>\n",
       "      <td>3.588012</td>\n",
       "      <td>8.045706</td>\n",
       "      <td>7.519759</td>\n",
       "      <td>41.814204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.682627</td>\n",
       "      <td>7.276673</td>\n",
       "      <td>7.977138</td>\n",
       "      <td>6.531673</td>\n",
       "      <td>3.725759</td>\n",
       "      <td>6.385145</td>\n",
       "      <td>6.569176</td>\n",
       "      <td>3.426667</td>\n",
       "      <td>4.972302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.603140</td>\n",
       "      <td>8.803433</td>\n",
       "      <td>113.438734</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>21.001327</td>\n",
       "      <td>8.978785</td>\n",
       "      <td>12.003550</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>6287.163151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.171540</td>\n",
       "      <td>12.009666</td>\n",
       "      <td>11.920312</td>\n",
       "      <td>11.970952</td>\n",
       "      <td>8.212275</td>\n",
       "      <td>9.622076</td>\n",
       "      <td>inf</td>\n",
       "      <td>8.066822</td>\n",
       "      <td>9.022207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Diagnosis    Anhedonia       Apathy     Appetite  Concentration  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
       "mean      0.505800     6.502860     2.478849    27.070029       6.519924   \n",
       "std       0.500016     1.488151     1.730810    14.202618       1.474846   \n",
       "min       0.000000     1.098854    -3.211011     0.141074       1.299964   \n",
       "25%       0.000000     5.495361     1.265128    16.724108       5.528181   \n",
       "50%       1.000000     6.485527     2.427409    25.165292       6.498042   \n",
       "75%       1.000000     7.489218     3.642059    35.447666       7.519759   \n",
       "max       1.000000    11.603140     8.803433   113.438734      11.649649   \n",
       "\n",
       "           Content     Delusion     Dep_Mood        Focus  Hallucination  ...  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000  ...   \n",
       "mean      0.279407     2.637389     5.727062     6.519924      65.073832  ...   \n",
       "std       0.834494     1.440347     3.284501     1.474846     223.943469  ...   \n",
       "min       0.000187    -2.127037     0.000000     1.299964       0.027350  ...   \n",
       "25%       0.018655     1.629919     4.678095     5.528181       4.113962  ...   \n",
       "50%       0.064259     2.558146     6.752196     6.498042      12.764604  ...   \n",
       "75%       0.215773     3.588012     8.045706     7.519759      41.814204  ...   \n",
       "max      21.001327     8.978785    12.003550    11.649649    6287.163151  ...   \n",
       "\n",
       "          Pregnant  Psychomotor   Rumination        Sleep       Stress  \\\n",
       "count  2762.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.101376     4.680583     5.685816     7.011266     4.916418   \n",
       "std       0.301880     1.482692     2.161891     1.410841     2.220262   \n",
       "min       0.000000    -0.024974    -0.409032     2.144726    -3.257788   \n",
       "25%       0.000000     3.697870     4.042552     6.058402     3.443683   \n",
       "50%       0.000000     4.720156     5.521805     6.980519     5.096416   \n",
       "75%       0.000000     5.682627     7.276673     7.977138     6.531673   \n",
       "max       1.000000    10.171540    12.009666    11.920312    11.970952   \n",
       "\n",
       "        Suspicious      Tension        Tired  Unusual_Thought   Withdrawal  \n",
       "count  2127.000000  5000.000000  5000.000000      5000.000000  5000.000000  \n",
       "mean      2.754909     4.920667          inf         2.480266     3.958121  \n",
       "std       1.496126     1.962342          NaN         1.410475     1.469444  \n",
       "min      -2.346238    -2.183456     0.366650        -1.981307    -0.825919  \n",
       "25%       1.703462     3.565482     4.491580         1.486439     2.969534  \n",
       "50%       2.735108     5.247353     5.513508         2.388994     3.962131  \n",
       "75%       3.725759     6.385145     6.569176         3.426667     4.972302  \n",
       "max       8.212275     9.622076          inf         8.066822     9.022207  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'Anhedonia',\n",
    " 'Apathy',\n",
    " 'Appetite',\n",
    " 'Concentration',\n",
    " 'Content',\n",
    " 'Delay',\n",
    " 'Delusion',\n",
    " 'Dep_Mood',\n",
    " 'Focus',\n",
    " 'Hallucination',\n",
    " 'Housing',\n",
    " 'Intrusive_Thoughts',\n",
    " 'Participant',\n",
    " 'Passive',\n",
    " 'Pregnant',\n",
    " 'Psychomotor',\n",
    " 'Race',\n",
    " 'Rumination',\n",
    " 'Sex',\n",
    " 'Sleep',\n",
    " 'Stress',\n",
    " 'Suspicious',\n",
    " 'Tension',\n",
    " 'Tired',\n",
    " 'Unusual_Thought',\n",
    " 'Withdrawal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/9g352cv10lv4vkg0vccmw9lc0000gn/T/ipykernel_43987/2552075687.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data.fillna(data.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#split the training and testing datasets\n",
    "y = data['Diagnosis']\n",
    "X = data[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "#X_test_save = X_test\n",
    "\n",
    "\n",
    "train = pd.concat([X_train,y_train], axis= 1)\n",
    "test = pd.concat([X_test,y_test], axis= 1)\n",
    "train = data_remove(train)\n",
    "test = data_remove(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anhedonia</th>\n",
       "      <th>Apathy</th>\n",
       "      <th>Appetite</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Content</th>\n",
       "      <th>Delusion</th>\n",
       "      <th>Dep_Mood</th>\n",
       "      <th>Focus</th>\n",
       "      <th>Hallucination</th>\n",
       "      <th>Intrusive_Thoughts</th>\n",
       "      <th>...</th>\n",
       "      <th>Psychomotor</th>\n",
       "      <th>Rumination</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Stress</th>\n",
       "      <th>Suspicious</th>\n",
       "      <th>Tension</th>\n",
       "      <th>Tired</th>\n",
       "      <th>Unusual_Thought</th>\n",
       "      <th>Withdrawal</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.507970</td>\n",
       "      <td>2.488079</td>\n",
       "      <td>27.030416</td>\n",
       "      <td>6.509845</td>\n",
       "      <td>0.271884</td>\n",
       "      <td>2.634363</td>\n",
       "      <td>5.694231</td>\n",
       "      <td>6.509845</td>\n",
       "      <td>67.487821</td>\n",
       "      <td>5.723364</td>\n",
       "      <td>...</td>\n",
       "      <td>4.683599</td>\n",
       "      <td>5.695334</td>\n",
       "      <td>7.010393</td>\n",
       "      <td>4.882908</td>\n",
       "      <td>2.740125</td>\n",
       "      <td>4.905160</td>\n",
       "      <td>5.508656</td>\n",
       "      <td>2.480740</td>\n",
       "      <td>3.954453</td>\n",
       "      <td>0.506226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.484693</td>\n",
       "      <td>1.730606</td>\n",
       "      <td>14.081542</td>\n",
       "      <td>1.486728</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>1.447198</td>\n",
       "      <td>3.299082</td>\n",
       "      <td>1.486728</td>\n",
       "      <td>238.685711</td>\n",
       "      <td>2.152243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476545</td>\n",
       "      <td>2.151656</td>\n",
       "      <td>1.412533</td>\n",
       "      <td>2.229810</td>\n",
       "      <td>0.980364</td>\n",
       "      <td>1.957935</td>\n",
       "      <td>1.495070</td>\n",
       "      <td>1.407826</td>\n",
       "      <td>1.464050</td>\n",
       "      <td>0.500034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.098854</td>\n",
       "      <td>-3.211011</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>1.578187</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-1.523586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.578187</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>-1.352806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123560</td>\n",
       "      <td>-0.409032</td>\n",
       "      <td>2.144726</td>\n",
       "      <td>-2.203737</td>\n",
       "      <td>-2.346238</td>\n",
       "      <td>-0.726664</td>\n",
       "      <td>0.687499</td>\n",
       "      <td>-1.981307</td>\n",
       "      <td>-0.825919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.496535</td>\n",
       "      <td>1.279946</td>\n",
       "      <td>16.757048</td>\n",
       "      <td>5.506803</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>1.616857</td>\n",
       "      <td>4.543235</td>\n",
       "      <td>5.506803</td>\n",
       "      <td>4.116464</td>\n",
       "      <td>4.357373</td>\n",
       "      <td>...</td>\n",
       "      <td>3.694768</td>\n",
       "      <td>4.065094</td>\n",
       "      <td>6.058726</td>\n",
       "      <td>3.395626</td>\n",
       "      <td>2.738788</td>\n",
       "      <td>3.545356</td>\n",
       "      <td>4.465110</td>\n",
       "      <td>1.492563</td>\n",
       "      <td>2.978531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.483684</td>\n",
       "      <td>2.438145</td>\n",
       "      <td>25.199759</td>\n",
       "      <td>6.468057</td>\n",
       "      <td>0.063716</td>\n",
       "      <td>2.549434</td>\n",
       "      <td>6.719571</td>\n",
       "      <td>6.468057</td>\n",
       "      <td>12.701013</td>\n",
       "      <td>5.720560</td>\n",
       "      <td>...</td>\n",
       "      <td>4.713601</td>\n",
       "      <td>5.536042</td>\n",
       "      <td>6.982103</td>\n",
       "      <td>5.061072</td>\n",
       "      <td>2.738788</td>\n",
       "      <td>5.208430</td>\n",
       "      <td>5.461856</td>\n",
       "      <td>2.390968</td>\n",
       "      <td>3.942145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.496072</td>\n",
       "      <td>3.633896</td>\n",
       "      <td>35.474871</td>\n",
       "      <td>7.520648</td>\n",
       "      <td>0.211474</td>\n",
       "      <td>3.590477</td>\n",
       "      <td>8.043615</td>\n",
       "      <td>7.520648</td>\n",
       "      <td>43.091082</td>\n",
       "      <td>6.989906</td>\n",
       "      <td>...</td>\n",
       "      <td>5.682510</td>\n",
       "      <td>7.276124</td>\n",
       "      <td>7.972515</td>\n",
       "      <td>6.510192</td>\n",
       "      <td>2.738788</td>\n",
       "      <td>6.372313</td>\n",
       "      <td>6.522500</td>\n",
       "      <td>3.412685</td>\n",
       "      <td>4.966916</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.603140</td>\n",
       "      <td>8.803433</td>\n",
       "      <td>98.888708</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>21.001327</td>\n",
       "      <td>7.545008</td>\n",
       "      <td>12.003550</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>6287.163151</td>\n",
       "      <td>13.209009</td>\n",
       "      <td>...</td>\n",
       "      <td>10.171540</td>\n",
       "      <td>11.851622</td>\n",
       "      <td>11.920312</td>\n",
       "      <td>11.219529</td>\n",
       "      <td>8.212275</td>\n",
       "      <td>9.562201</td>\n",
       "      <td>11.454125</td>\n",
       "      <td>8.066822</td>\n",
       "      <td>9.022207</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Anhedonia       Apathy     Appetite  Concentration      Content  \\\n",
       "count  3453.000000  3453.000000  3453.000000    3453.000000  3453.000000   \n",
       "mean      6.507970     2.488079    27.030416       6.509845     0.271884   \n",
       "std       1.484693     1.730606    14.081542       1.486728     0.844086   \n",
       "min       1.098854    -3.211011     0.141074       1.578187     0.000187   \n",
       "25%       5.496535     1.279946    16.757048       5.506803     0.018019   \n",
       "50%       6.483684     2.438145    25.199759       6.468057     0.063716   \n",
       "75%       7.496072     3.633896    35.474871       7.520648     0.211474   \n",
       "max      11.603140     8.803433    98.888708      11.649649    21.001327   \n",
       "\n",
       "          Delusion     Dep_Mood        Focus  Hallucination  \\\n",
       "count  3453.000000  3453.000000  3453.000000    3453.000000   \n",
       "mean      2.634363     5.694231     6.509845      67.487821   \n",
       "std       1.447198     3.299082     1.486728     238.685711   \n",
       "min      -1.523586     0.000000     1.578187       0.027350   \n",
       "25%       1.616857     4.543235     5.506803       4.116464   \n",
       "50%       2.549434     6.719571     6.468057      12.701013   \n",
       "75%       3.590477     8.043615     7.520648      43.091082   \n",
       "max       7.545008    12.003550    11.649649    6287.163151   \n",
       "\n",
       "       Intrusive_Thoughts  ...  Psychomotor   Rumination        Sleep  \\\n",
       "count         3453.000000  ...  3453.000000  3453.000000  3453.000000   \n",
       "mean             5.723364  ...     4.683599     5.695334     7.010393   \n",
       "std              2.152243  ...     1.476545     2.151656     1.412533   \n",
       "min             -1.352806  ...     0.123560    -0.409032     2.144726   \n",
       "25%              4.357373  ...     3.694768     4.065094     6.058726   \n",
       "50%              5.720560  ...     4.713601     5.536042     6.982103   \n",
       "75%              6.989906  ...     5.682510     7.276124     7.972515   \n",
       "max             13.209009  ...    10.171540    11.851622    11.920312   \n",
       "\n",
       "            Stress   Suspicious      Tension        Tired  Unusual_Thought  \\\n",
       "count  3453.000000  3453.000000  3453.000000  3453.000000      3453.000000   \n",
       "mean      4.882908     2.740125     4.905160     5.508656         2.480740   \n",
       "std       2.229810     0.980364     1.957935     1.495070         1.407826   \n",
       "min      -2.203737    -2.346238    -0.726664     0.687499        -1.981307   \n",
       "25%       3.395626     2.738788     3.545356     4.465110         1.492563   \n",
       "50%       5.061072     2.738788     5.208430     5.461856         2.390968   \n",
       "75%       6.510192     2.738788     6.372313     6.522500         3.412685   \n",
       "max      11.219529     8.212275     9.562201    11.454125         8.066822   \n",
       "\n",
       "        Withdrawal    Diagnosis  \n",
       "count  3453.000000  3453.000000  \n",
       "mean      3.954453     0.506226  \n",
       "std       1.464050     0.500034  \n",
       "min      -0.825919     0.000000  \n",
       "25%       2.978531     0.000000  \n",
       "50%       3.942145     1.000000  \n",
       "75%       4.966916     1.000000  \n",
       "max       9.022207     1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = ['Sex','Race','Housing','Delay']\n",
    "\n",
    "def onehot(data, categories = categories):\n",
    "    ordinalencoder = OneHotEncoder()\n",
    "    onehot = ordinalencoder.fit_transform(data[categories])\n",
    "    columns = []\n",
    "    for i, values in enumerate(ordinalencoder.categories_):\n",
    "        for j in values:\n",
    "            columns. append(categories[i]+'-'+j)\n",
    "    return pd.DataFrame(onehot.toarray(), columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Diagnosis\n",
       "2858          0\n",
       "1559          1\n",
       "1441          1\n",
       "2179          0\n",
       "1390          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = X_train.join(onehot(X_train))\n",
    "#X_test = X_test.join(onehot(X_test))\n",
    "X_train = pd.get_dummies(train[features], columns = categories)\n",
    "X_test = pd.get_dummies(test[features], columns = categories)\n",
    "y_train = train[['Diagnosis']]\n",
    "y_test = test[['Diagnosis']]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahaixing/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dahaixing/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Logistc regression training \n",
    "\n",
    "LGmodel = LogisticRegression(penalty='elasticnet', max_iter= 1000, solver= 'saga', l1_ratio=1)\n",
    "\n",
    "LGmodel.fit(X_train, y_train)\n",
    "\n",
    "LG_test_predict = LGmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG test accuracy: 0.8878378378378379\n"
     ]
    }
   ],
   "source": [
    "print('LG test accuracy:', skm.accuracy_score(y_test, LG_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89       741\n",
      "           0       0.89      0.89      0.89       739\n",
      "\n",
      "    accuracy                           0.89      1480\n",
      "   macro avg       0.89      0.89      0.89      1480\n",
      "weighted avg       0.89      0.89      0.89      1480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, LG_test_predict, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[656  85]\n",
      " [ 81 658]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, LG_test_predict, labels=[1, 0])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairlearn\n",
    "from fairlearn.metrics import MetricFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_fp(truelabels, predictions):\n",
    "  sesitive = test.Race\n",
    "  fmetrics = MetricFrame(metrics= fairlearn.metrics.false_positive_rate, \n",
    "                         y_true=truelabels, \n",
    "                         y_pred=predictions,\n",
    "                         sensitive_features=sesitive)\n",
    "  results = pd.DataFrame([fmetrics.by_group, fmetrics.by_group/fmetrics.by_group.White], \n",
    "                         index= ['FPR', 'FPR Parity'])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.065693</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR Parity</th>\n",
       "      <td>0.821168</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>1.356589</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race           Asian     Black  Hispanic  White\n",
       "FPR         0.065693  0.181818  0.108527   0.08\n",
       "FPR Parity  0.821168  2.272727  1.356589   1.00"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_fp(y_test, LG_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raceNsex_fp(truelabels, predictions):\n",
    "  sesitive = pd.DataFrame(np.stack([test.Race, test.Sex], axis = 1),\n",
    "                          columns = ['Race','Sex']) \n",
    "  fmetrics = MetricFrame(metrics= fairlearn.metrics.false_positive_rate, \n",
    "                         y_true=truelabels, \n",
    "                         y_pred=predictions,\n",
    "                         sensitive_features=sesitive)\n",
    "  results = pd.DataFrame([fmetrics.by_group, fmetrics.by_group/fmetrics.by_group.White.Male], \n",
    "                         index= ['FPR', 'FPR Parity'])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Asian</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Black</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hispanic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.194969</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR Parity</th>\n",
       "      <td>0.416748</td>\n",
       "      <td>0.709549</td>\n",
       "      <td>1.604741</td>\n",
       "      <td>1.055227</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>1.107988</td>\n",
       "      <td>0.440934</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race           Asian               Black            Hispanic            \\\n",
       "Sex           Female      Male    Female      Male    Female      Male   \n",
       "FPR         0.050633  0.086207  0.194969  0.128205  0.090909  0.134615   \n",
       "FPR Parity  0.416748  0.709549  1.604741  1.055227  0.748252  1.107988   \n",
       "\n",
       "Race           White            \n",
       "Sex           Female      Male  \n",
       "FPR         0.053571  0.121495  \n",
       "FPR Parity  0.440934  1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raceNsex_fp(y_test, LG_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_fn(truelabels, predictions):\n",
    "  sesitive = test.Race\n",
    "  fmetrics = MetricFrame(metrics= fairlearn.metrics.false_negative_rate, \n",
    "                         y_true=truelabels, \n",
    "                         y_pred=predictions,\n",
    "                         sensitive_features=sesitive)\n",
    "  results = pd.DataFrame([fmetrics.by_group, fmetrics.by_group/fmetrics.by_group.White], \n",
    "                         index= ['FNR', 'FNR Parity'])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.091195</td>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.136546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR Parity</th>\n",
       "      <td>0.823897</td>\n",
       "      <td>0.667869</td>\n",
       "      <td>1.012829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race           Asian     Black  Hispanic     White\n",
       "FNR         0.112500  0.091195  0.138298  0.136546\n",
       "FNR Parity  0.823897  0.667869  1.012829  1.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_fn(y_test, LG_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raceNsex_fn(truelabels, predictions):\n",
    "  sesitive = pd.DataFrame(np.stack([test.Race, test.Sex], axis = 1),\n",
    "                          columns = ['Race','Sex']) \n",
    "  fmetrics = MetricFrame(metrics= fairlearn.metrics.false_negative_rate, \n",
    "                         y_true=truelabels, \n",
    "                         y_pred=predictions,\n",
    "                         sensitive_features=sesitive)\n",
    "  results = pd.DataFrame([fmetrics.by_group, fmetrics.by_group/fmetrics.by_group.White.Male], \n",
    "                         index= ['FNR', 'FNR Parity'])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Asian</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Black</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hispanic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR Parity</th>\n",
       "      <td>1.674419</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>2.242991</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>2.448980</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race           Asian               Black            Hispanic            \\\n",
       "Sex           Female      Male    Female      Male    Female      Male   \n",
       "FNR         0.139535  0.081081  0.186916  0.042654  0.204082  0.066667   \n",
       "FNR Parity  1.674419  0.972973  2.242991  0.511848  2.448980  0.800000   \n",
       "\n",
       "Race           White            \n",
       "Sex           Female      Male  \n",
       "FNR         0.177305  0.083333  \n",
       "FNR Parity  2.127660  1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raceNsex_fn(y_test, LG_test_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model = DecisionTreeClassifier()\n",
    "DT_model = DT_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_test_predictions = DT_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT test accuracy: 0.856081081081081\n"
     ]
    }
   ],
   "source": [
    "print('DT test accuracy:', skm.accuracy_score(y_test, DT_test_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahaixing/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model = svm_model.fit(X_train, y_train)\n",
    "svm_test_predictions = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM test accuracy: 0.9283783783783783\n"
     ]
    }
   ],
   "source": [
    "print('SVM test accuracy:', skm.accuracy_score(y_test, svm_test_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1748, number of negative: 1705\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5123\n",
      "[LightGBM] [Info] Number of data points in the train set: 3453, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506226 -> initscore=0.024907\n",
      "[LightGBM] [Info] Start training from score 0.024907\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {'objective': 'binary', 'metric': 'binary_logloss'}\n",
    "LGB_model = lgb.train(params, train_data)\n",
    "# Predict on the test data\n",
    "LGB_test_predictions = LGB_model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to binary labels\n",
    "LGB_test_predictions = (LGB_test_predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGN test accuracy: 0.9398648648648649\n"
     ]
    }
   ],
   "source": [
    "print('LGB test accuracy:', skm.accuracy_score(y_test, LGB_test_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose Light GBM as classification model, next we do cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/9g352cv10lv4vkg0vccmw9lc0000gn/T/ipykernel_43987/2552075687.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data.fillna(data.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cv_data = data\n",
    "cv_data = data_remove(cv_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cv_data[['Diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anhedonia</th>\n",
       "      <th>Apathy</th>\n",
       "      <th>Appetite</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Content</th>\n",
       "      <th>Delusion</th>\n",
       "      <th>Dep_Mood</th>\n",
       "      <th>Focus</th>\n",
       "      <th>Hallucination</th>\n",
       "      <th>Intrusive_Thoughts</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>Race_Black</th>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <th>Race_White</th>\n",
       "      <th>Housing_Stable</th>\n",
       "      <th>Housing_Unstable</th>\n",
       "      <th>Delay_No</th>\n",
       "      <th>Delay_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.503788</td>\n",
       "      <td>2.474579</td>\n",
       "      <td>27.055055</td>\n",
       "      <td>6.516107</td>\n",
       "      <td>0.279476</td>\n",
       "      <td>2.634954</td>\n",
       "      <td>5.704499</td>\n",
       "      <td>6.516107</td>\n",
       "      <td>64.269048</td>\n",
       "      <td>5.706271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553010</td>\n",
       "      <td>0.446990</td>\n",
       "      <td>0.141091</td>\n",
       "      <td>0.347659</td>\n",
       "      <td>0.142307</td>\n",
       "      <td>0.368944</td>\n",
       "      <td>0.934523</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0.515102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.489300</td>\n",
       "      <td>1.730684</td>\n",
       "      <td>14.175538</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.833005</td>\n",
       "      <td>1.439073</td>\n",
       "      <td>3.297262</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>219.312738</td>\n",
       "      <td>2.169768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>0.348150</td>\n",
       "      <td>0.476275</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.482568</td>\n",
       "      <td>0.247391</td>\n",
       "      <td>0.247391</td>\n",
       "      <td>0.499823</td>\n",
       "      <td>0.499823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.098854</td>\n",
       "      <td>-3.211011</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>1.299964</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-2.127037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.299964</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>-1.386416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.491980</td>\n",
       "      <td>1.262008</td>\n",
       "      <td>16.674792</td>\n",
       "      <td>5.524455</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>1.626144</td>\n",
       "      <td>4.635510</td>\n",
       "      <td>5.524455</td>\n",
       "      <td>4.104303</td>\n",
       "      <td>4.283100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.485558</td>\n",
       "      <td>2.427466</td>\n",
       "      <td>25.137850</td>\n",
       "      <td>6.491856</td>\n",
       "      <td>0.064289</td>\n",
       "      <td>2.556736</td>\n",
       "      <td>6.744049</td>\n",
       "      <td>6.491856</td>\n",
       "      <td>12.731402</td>\n",
       "      <td>5.702358</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.489204</td>\n",
       "      <td>3.633896</td>\n",
       "      <td>35.464840</td>\n",
       "      <td>7.517627</td>\n",
       "      <td>0.216074</td>\n",
       "      <td>3.587206</td>\n",
       "      <td>8.042209</td>\n",
       "      <td>7.517627</td>\n",
       "      <td>41.776438</td>\n",
       "      <td>6.969119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.603140</td>\n",
       "      <td>8.803433</td>\n",
       "      <td>98.888708</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>21.001327</td>\n",
       "      <td>8.978785</td>\n",
       "      <td>12.003550</td>\n",
       "      <td>11.649649</td>\n",
       "      <td>6287.163151</td>\n",
       "      <td>13.209009</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Anhedonia       Apathy     Appetite  Concentration      Content  \\\n",
       "count  4933.000000  4933.000000  4933.000000    4933.000000  4933.000000   \n",
       "mean      6.503788     2.474579    27.055055       6.516107     0.279476   \n",
       "std       1.489300     1.730684    14.175538       1.477503     0.833005   \n",
       "min       1.098854    -3.211011     0.141074       1.299964     0.000187   \n",
       "25%       5.491980     1.262008    16.674792       5.524455     0.018579   \n",
       "50%       6.485558     2.427466    25.137850       6.491856     0.064289   \n",
       "75%       7.489204     3.633896    35.464840       7.517627     0.216074   \n",
       "max      11.603140     8.803433    98.888708      11.649649    21.001327   \n",
       "\n",
       "          Delusion     Dep_Mood        Focus  Hallucination  \\\n",
       "count  4933.000000  4933.000000  4933.000000    4933.000000   \n",
       "mean      2.634954     5.704499     6.516107      64.269048   \n",
       "std       1.439073     3.297262     1.477503     219.312738   \n",
       "min      -2.127037     0.000000     1.299964       0.027350   \n",
       "25%       1.626144     4.635510     5.524455       4.104303   \n",
       "50%       2.556736     6.744049     6.491856      12.731402   \n",
       "75%       3.587206     8.042209     7.517627      41.776438   \n",
       "max       8.978785    12.003550    11.649649    6287.163151   \n",
       "\n",
       "       Intrusive_Thoughts  ...   Sex_Female     Sex_Male   Race_Asian  \\\n",
       "count         4933.000000  ...  4933.000000  4933.000000  4933.000000   \n",
       "mean             5.706271  ...     0.553010     0.446990     0.141091   \n",
       "std              2.169768  ...     0.497232     0.497232     0.348150   \n",
       "min             -1.386416  ...     0.000000     0.000000     0.000000   \n",
       "25%              4.283100  ...     0.000000     0.000000     0.000000   \n",
       "50%              5.702358  ...     1.000000     0.000000     0.000000   \n",
       "75%              6.969119  ...     1.000000     1.000000     0.000000   \n",
       "max             13.209009  ...     1.000000     1.000000     1.000000   \n",
       "\n",
       "        Race_Black  Race_Hispanic   Race_White  Housing_Stable  \\\n",
       "count  4933.000000    4933.000000  4933.000000     4933.000000   \n",
       "mean      0.347659       0.142307     0.368944        0.934523   \n",
       "std       0.476275       0.349400     0.482568        0.247391   \n",
       "min       0.000000       0.000000     0.000000        0.000000   \n",
       "25%       0.000000       0.000000     0.000000        1.000000   \n",
       "50%       0.000000       0.000000     0.000000        1.000000   \n",
       "75%       1.000000       0.000000     1.000000        1.000000   \n",
       "max       1.000000       1.000000     1.000000        1.000000   \n",
       "\n",
       "       Housing_Unstable     Delay_No    Delay_Yes  \n",
       "count       4933.000000  4933.000000  4933.000000  \n",
       "mean           0.065477     0.484898     0.515102  \n",
       "std            0.247391     0.499823     0.499823  \n",
       "min            0.000000     0.000000     0.000000  \n",
       "25%            0.000000     0.000000     0.000000  \n",
       "50%            0.000000     0.000000     1.000000  \n",
       "75%            0.000000     1.000000     1.000000  \n",
       "max            1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = pd.get_dummies(cv_data[features], columns = categories)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the LightGBM parameters\n",
    "params = {'objective': 'binary', 'metric': 'binary_logloss'}\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store the accuracy scores\n",
    "scores = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f9a985f1847f0e8a16535ea7bae5682c17fbf69f04049eaef13610fb13a3a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
